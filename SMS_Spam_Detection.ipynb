{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SMS Spam Detection.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S57J-1HgAanL",
        "colab_type": "text"
      },
      "source": [
        "#SMS SPAM CLASSIFICATION USING NLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7ODf47fS3IR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNbo-l23TcsY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1931b6a2-62e3-4c56-99d9-f450229c72c2"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('stepwords')\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Error loading stepwords: Package 'stepwords' not found in\n",
            "[nltk_data]     index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJvufFIVTk7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reading Data from the Google Drive by labelling them as Spam/not and Messages\n",
        "\n",
        "#reading data from Google drive\n",
        "#data = pd.read_csv('/content/drive/My Drive/Deep Learning/NLP/SMS Spam Not Collection/SMSSpamCollection',sep=\"\\t\", names=['spam/not','messages'])\n",
        "\n",
        "#reading data from specified path\n",
        "data = pd.read_csv('/content/SMSSpamCollection',sep=\"\\t\", names=['spam/not','messages'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTEsjsIHVSs5",
        "colab_type": "text"
      },
      "source": [
        "##Classification Using PorterStemmer and Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHKWC-1jUjAD",
        "colab_type": "code",
        "outputId": "651c4552-294e-4b94-a187-2c819f07c931",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#defining object for PorterStemmer \n",
        "ps = PorterStemmer()\n",
        "\n",
        "#defing object for Lemmatization\n",
        "lem = WordNetLemmatizer()\n",
        "#creating list for cleaned Data \n",
        "cleaned_data = []\n",
        "data.shape\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5572, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSpQLBtEfKFI",
        "colab_type": "code",
        "outputId": "1be09314-3f5a-4aba-9d1f-aab8d5262ff8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#data['messages'].shape\n",
        "len(data)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5572"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ru3mUI4yYzTd",
        "colab_type": "text"
      },
      "source": [
        "###Cleaning the data by using stepwords and regular Expressions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWL6-rNOWAqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#iterating through data set\n",
        "for i in range(len(data)):\n",
        "  res = re.sub('^a-zA-Z0-9','',data['messages'][i]) #removing all letters other than a-z or A-Z or 0-9\n",
        "  res = res.lower() #converting all into lower case\n",
        "  res = res.split() #splitting every sentence into words\n",
        "  \n",
        "  #res = [ps.stem(j) for j in res if not j in stepwords.words('english')] #using stepwords to remove unuseful words\n",
        "  #res = [lem.lemmatise(j) for j in res if not j in stepwords.words('english')]\n",
        "  \n",
        "  res = ''.join(res) #concating the word to form a sentence(same as above)\n",
        "  \n",
        "  cleaned_data.append(res) #storing all sentences into the cleaned_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlKU3yWqc6IP",
        "colab_type": "code",
        "outputId": "fe666120-8960-4308-f664-aa9234768ea2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(cleaned_data)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5572"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGYIgz0hZEY0",
        "colab_type": "text"
      },
      "source": [
        "###Creating the BAG OF WORDS Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHsF7TnRXrez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "#importing CountVectorizer from sklearn to create bag of words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ryfoU8yZXQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating cv with top 6000 features from bag of words\n",
        "cv = CountVectorizer(max_features=6000)\n",
        "\n",
        "#creating the dataset in the form of numerical values\n",
        "X = cv.fit_transform(cleaned_data).toarray()\n",
        "\n",
        "y = pd.get_dummies(data['spam/not']) #converting the categorical values into dummylabels\n",
        "y.head()\n",
        "\n",
        "y = y.iloc[:,1].values #selecting only one column which specifies it is spam if it contains 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_3zhQvYcfJW",
        "colab_type": "code",
        "outputId": "fab7101f-cc30-41f9-e78b-d1598e80508b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(y.shape)\n",
        "print(X.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5572,)\n",
            "(5572, 6000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Er2wn2hQbsB5",
        "colab_type": "text"
      },
      "source": [
        "###Creating Model for evaluation of Spam/Not Spam Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oq6fUJElaCv_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OBRzk3Z_hzm",
        "colab_type": "text"
      },
      "source": [
        "###Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIcDkYyhbFLt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1a6e9ef2-3f36-4e85-d8e6-adff94d3df2e"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "model = MultinomialNB()\n",
        "\n",
        "model = model.fit(X_train,y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(accuracy*100)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "95.69506726457399\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ou2NjqC_q-R",
        "colab_type": "text"
      },
      "source": [
        "###Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DU4u_KtP_Kjz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression()\n",
        "\n",
        "model = model.fit(X_train,y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(accuracy*100)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}